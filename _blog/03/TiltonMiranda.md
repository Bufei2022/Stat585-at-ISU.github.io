---
title: "Blog 3: Ethics and Reproducibility..."
author: "Miranda Tilton"
topic: "03"
layout: post
root: ../../../
---

1. **Pick one of the papers Retraction Watch features on their website and describe what went wrong**. 

I read [this article](https://retractionwatch.com/2018/11/28/psychology-journal-to-retract-study-claiming-that-people-fear-contagion-less-in-the-dark/) about the study retracted from *Psychological Science* that claimed that people in dark rooms or wearing sunglasses are less fearful of contracting contagious diseases. The paper referenced 5 studies that the two lead authors, Ping Dong and Chen-Bo Zhong, conducted "in both laboratory and real-life settings". The researchers conducted study 3 at the request of the journal, to strengthen their findings, and made all study data and materials public for the purpose of transparency and reproducibility. Unfortunately, a reader of the journal pointed out to the editor that the time stamps on the data for studies 1 and 3 showed that enviroment effects were highly confounded with the date each condition was tested due to the researchers' design of blocks. Since there was no proof that the difference in fear of disease was not due to different dates (e.g., people are more fearful of contracting the flu during certain months), the editor and authors decided to retract the paper. In this case, there was no malicious intent and the authors told Retraction Watch that they are planning another study to fix their errors and show the effect they previously claimed, but their error shows the importance of transparency and also of strong a sttrong statistical foudnation in experiments.

2. **After reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not follow in your future projects.**

I am very comfortable with recording data manipulation steps and rarely have any need for manual manipulation (especially using R), so Rule #2 does not seem difficult to follow. On the other hand, I think I'll have a very hard time remembering to record versions of programs, especially with certain packages in R. Considering my work with neural networks, there are a number of external sources that are used throughout my work and I usually just trust that they will continue to work as I expect. I see the logic in recording version information, but for work over a long period of time, and when Susan VanderPlas also controls a large aspect of the computing power in my current research (and thus versioning and updating decision-making), I just don't view Rule #3 as especially high on my list of priorities.
