---
title: "Blog # 5: More on Reproducibility..."
author: "Brianna Lawton"
topic: "05"
layout: post
root: ../../../
---

## Blog 5 Responses

1. **Answer each of the following questions with at least 2-3 sentences.**

    1. **Summarize Roger Peng's outline for reproducibility in** *Biostatistics*. 
In Roger Peng's editorial, he describes how many people are jumping on the bandwagon of reproducible research but he begins to explain how many scientific investogations within fields of study can't be fully replicated because of a lack of time or resources. He goes on to list reasons why there is a need to publish reproducible research, some being: reports of fraudulent research being published, analyses can become complicated and the possibility of unintentional errors resulting in misleading findings, and misunderstandings about commonly used software that is used in a way not intended or defined. 

While there seems to be many benefits of research reproducibility, Peng discussed some disadvantages being: general lack of infrastructure to house this open data, several barriers that investgators encounter with the ability to distribute and make available their materials to reproduce the research for an indefinite amount of time, and lack of an “instruction manual” that indicates which materials are needed and what might be the most suitable formats for making data and computer code available.

Therefore, Peng  proposed a minimum standard that can fill the void between full replication and nothing.His idea of "reproducible research" consisted of 3 parts:
1. Data:analytic data used to draw conclusions are made available on the journal's website
2. Code:all code used to produce published results is provided
3. Reproducibility:the AER* must succeed in executing the code on the data provided and produces results matching those that the authors claim are reproducible.
The Associate Editor for Reproducibility (AER) will handle submissions of reproducible articles. The AER was usually only involved with a submission only when an article had been accepted for publication but Peng suggested that the AER will consider three different criteria (as listed above) when evaluating the reproducibility of an article.

    2. **What are Keiding's main criticisms of the proposal?**.
Keiding's main criticisms of Peng's proposal is that Peng is somewhat contradicting himself by encouraging researchers to conduct “alternative analyses” but this idea shys away from "reproducibility" and more new methodology development.Second, Keiding discusses that just being able to rerun calculations and checking if they're correct isnt't enough, he's suggesting that there's alot more background analysis and substantiative contextual info to be looked into. Keiding also thinks it is impratical to create a reanalyis/reproducibility template to draw conclusions for whole processes that encompasses many statisticians inputing their concrete and insightful judgement. Keiding criticizes how Peng deminishes the idea that background context about the data is minor and that all statisticians across the board will understand the data and move forward to try to reproduce it. Keiding scolds Peng's assumption that only if needed, statistician will need additional data and information from time to time to figure it out--Keiding implys that helpful such files and data should already be included.

    3. **Which point in the commentaries speaks to you the most? Why?**
The commentary from D. R. Cox; Christl Donnelly spoke to me the most because it reasoned out logic of advantages and disadvantages of the idea of reproducibility. They mention that the proposals for Biostatistics are to be welcomed even though their name and objectives are misformulated. The idea of using data to illustrate the performance of statistical methods and using statistical methods to extract important subject-matter information from data involves subtle considerations about the interaction between subject-matter and statistical aspects and the detailed nature of the data and its compilation.

I like the perspective of when they stated that if a journal is requiring independent replication of specific statistical analyses as a general check before publication but not combing deeper and considering the topic, data type, etc. then it seems not merely unnecessary but a misuse of relatively scarce expertise to expect reproducibility.


    4. **How does Keiding respond to the commentary you picked. What are his main points in his response?**
Keiding responds to Cox & Donnelly by stating that her is very grateful to all the discussants of his letter to the editor--he boldly acknowledges that he didn't receive much push back. Keiding reinforced his response by summarizing his main points that there is a need to focus on problem-driven research in biostatistics, and reanalyses of old data sets detached from their original context because it runs a risk of alienating the methodological developments from the problems they were intended to help solve. Following up with his second point that high-quality applied statistical work is collaborative between the statistician and the substantive researchers. He sarcastically remarks that this can't be if people of retrieving data from repos. 

    
2. **Describe your experience with a data intensive (collaborative) project. What are the most prominent issues with ensuring reproducibility of research results (focus on data related aspects)? What would you do differently if you could go back in time?**

I would say a prominent issue with ensuring reproducibility of research results is if working in a research group (majority of the time) to make sure that everyone is following the same protocols for cleaning the data, coding the data, interpreting variables and results, consistent offset or margin of error factors, etc. This can cause human error and unintended manipulation in the data and results--therefore slowing down progress or having to start the process over again. 

