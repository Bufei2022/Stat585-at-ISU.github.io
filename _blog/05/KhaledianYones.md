---
title: "More on Reproducibility..."
author: "Yones Khaledian"
topic: "05"
layout: post
root: ../../../
---

## Background:


In 2009 one of the associate editors of Biostatistics, Roger Peng, outlined a new policy of [reproducibility](https://doi.org/10.1093/biostatistics/kxp014) for the journal. 

This triggered a response from one of the other associated editors, Niels Keiding, and subsequently a large part of volume 11, issue 3 of Biostatistics was dedicated to a discussion of issues of redproducibility. 

## Prompt:

Read through 

- Roger Peng's [initial editorial](https://doi.org/10.1093/biostatistics/kxp014), 

- [Keiding's response](https://doi.org/10.1093/biostatistics/kxq033),

- its five [commentaries](https://academic.oup.com/biostatistics/issue/11/3),  

- Roger Peng's [response to Keiding](https://doi.org/10.1093/biostatistics/kxq032)

- and finally, Keiding's [response to the commentaries](https://doi.org/10.1093/biostatistics/kxq034)

Don't worry about the number of papers listed - these papers are all very short and easy reads. 


Write a blog post addressing the questions: 

1. **Answer each of the following questions with at least 2-3 sentences.**

    1. **Summarize Roger Peng's outline for reproducibility in** *Biostatistics*. 
  
  -	There are some benefits to reproduce research in Biostatistics, while there are still some barrier, such as      requiring amount of time to do so and lack of an instruction manual. 
  -	Required criteria for reproducibility are to share 1) the data and 2) code. Also, the others should produce      the results with same data and code.
  -	The authors should mention that they intend to submit supplementary materials to show that others are            permission to partially or fully reproduce their work. 
  
    
    2. **What are Keiding's main criticisms of the proposal?**. 
    
  Niels disagrees with the term reproducible when the purpose of a research is to develop a new methodology. He    also mentions that there is more to do research than a statistical analysis or correction of calculation.        Therefore, he concludes that reproducibility would not helpful for science.  
    
    3. **Which point in the commentaries speaks to you the most? Why?**
  The reproducibility is a minimum standard in the context of scientific validation. I think that it is a good     point. Each data is produced based on different purposes. Reproducibility would be useful, but it is unfair to   weigh much on it.    

    4. **How does Keiding respond to the commentary you picked. What are his main points in his response?**
  Reanalyzing old data increases the risk of alienating the methodological development from the problem the        others try to solve. 
  In order to provide high quality statistical works, better documentation of the computations will be useful.  

  He believes that the final publication should provide a comprehensive explanation regarding methodological as    well as the substantive point of view. At the end of the paper, he says that unfortunately authors do not feel   unhappy about not understanding the substantive detail in their examples they provide. And many editors pay      little attention to this issue.

    
2. **Describe your experience with a data intensive (collaborative) project. What are the most prominent issues with ensuring reproducibility of research results (focus on data related aspects)? What would you do differently if you could go back in time?**

  My major is soil science. The soil system is a complicated system. I think that reproducibility is not easy in   this major. Because researchers take soil sample based on different purposes. And to analyze the data, they      should choose the statistical methodology before taking sample. Trying an alternative analyses is not a good     idea. I do not claim that it is not practical, however, I prefer to select statistical analysis before taking    soil samples, as soil sampling is very expensive. However, reproducibility would work well with legacy data in  my major. 
